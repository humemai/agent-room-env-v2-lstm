env_str: room_env:RoomEnv-v2
num_episodes: 10
num_rollouts: 50
epoch_per_rollout: 32
batch_size: 64
gamma: 0.698904384296727
lam: 0.928046136392738
epsilon: 0.24570973765644039
entropy_weight: 0.06654810999562656
capacity:
  episodic: 16
  episodic_agent: 0
  semantic: 16
  semantic_map: 0
  short: 1
pretrain_semantic: false
nn_params:
  hidden_size: 64
  num_layers: 2
  embedding_dim: 64
  make_categorical_embeddings: false
  v1_params: null
  v2_params: {}
  memory_of_interest:
  - episodic
  - semantic
  - short
  fuse_information: sum
  include_positional_encoding: true
  max_timesteps: 100
  max_strength: 100
run_test: true
num_samples_for_results: 10
train_seed: 5
test_seed: 0
device: cpu
qa_policy: episodic_semantic
explore_policy: avoid_walls
env_config:
  question_prob: 1.0
  terminates_at: 99
  randomize_observations: objects
  room_size: l
  rewards:
    correct: 1
    wrong: 0
    partial: 0
  make_everything_static: false
  num_total_questions: 1000
  question_interval: 1
  include_walls_in_observations: true
split_reward_training: false
default_root_dir: ./training_results/PPO/mm/
run_handcrafted_baselines: null
