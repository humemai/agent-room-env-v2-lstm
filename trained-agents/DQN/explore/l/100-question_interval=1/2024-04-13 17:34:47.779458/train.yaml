env_str: room_env:RoomEnv-v2
num_iterations: 10000
replay_buffer_size: 10000
warm_start: 1000
batch_size: 32
target_update_interval: 10
epsilon_decay_until: 10000
max_epsilon: 1.0
min_epsilon: 0.1
gamma: 0.9
capacity:
  episodic: 16
  episodic_agent: 0
  semantic: 16
  semantic_map: 0
  short: 1
pretrain_semantic: false
nn_params:
  hidden_size: 64
  num_layers: 2
  embedding_dim: 64
  make_categorical_embeddings: false
  memory_of_interest:
  - episodic
  - semantic
  fuse_information: sum
  include_positional_encoding: true
  max_timesteps: 100
  max_strength: 100
run_test: true
num_samples_for_results: 10
plotting_interval: 10
train_seed: 9
test_seed: 4
device: cpu
mm_policy: neural
mm_agent_path: ./training-results/stochastic-objects/DQN/mm/l/100-question_interval=1/2024-04-13
  12:57:42.589074/agent.pkl
qa_policy: episodic_semantic
env_config:
  question_prob: 1.0
  terminates_at: 99
  randomize_observations: objects
  room_size: l
  rewards:
    correct: 1
    wrong: 0
    partial: 0
  make_everything_static: false
  num_total_questions: 1000
  question_interval: 1
  include_walls_in_observations: true
  deterministic_objects: false
ddqn: true
dueling_dqn: false
default_root_dir: ./training-results/stochastic-objects/DQN/explore/l/100-question_interval=1
run_neural_baseline: true
run_handcrafted_baselines: true
