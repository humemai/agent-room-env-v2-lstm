{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MM / explore with random sampling for HP tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import os\n",
    "from agent import DQNAgent\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# Number of combinations you want\n",
    "num_combinations = 5  # Change this to however many combinations you need\n",
    "\n",
    "# default\n",
    "room_size = \"xl-different-prob\"\n",
    "capacity_max = 6\n",
    "batch_size = 32\n",
    "terminates_at = 99\n",
    "num_iterations = (terminates_at + 1) * 100\n",
    "validation_starts_at = num_iterations // 2\n",
    "\n",
    "prob_type = (\n",
    "    \"non-equal-object-probs\" if \"different-prob\" in room_size else \"equal-object-probs\"\n",
    ")\n",
    "root_path = (\n",
    "    f\"./training-results/{prob_type}/dqn/room_size={room_size}/capacity={capacity_max}/\"\n",
    ")\n",
    "\n",
    "# random\n",
    "test_seed_ = [i for i in range(100)]\n",
    "target_update_interval_ = [10]\n",
    "min_epsilon_ = [0.1]\n",
    "gamma_mm_ = [0.99]\n",
    "gamma_explore_ = [0.9]\n",
    "semantic_decay_factor_ = [0.70]\n",
    "\n",
    "# Weights for agent_capacity_ elements\n",
    "agent_capacity_weights = [0, 0, 1]\n",
    "agent_capacity_ = [\n",
    "    {\"episodic\": capacity_max // 2, \"semantic\": capacity_max // 2, \"short\": 1},\n",
    "    {\"episodic\": capacity_max, \"semantic\": 0, \"short\": 1},\n",
    "    {\"episodic\": 0, \"semantic\": capacity_max, \"short\": 1},\n",
    "]\n",
    "replay_buffer_size_ = [\n",
    "    # num_iterations,\n",
    "    num_iterations\n",
    "    // 2,\n",
    "]\n",
    "warm_start_ = [\n",
    "    # num_iterations // 2,\n",
    "    num_iterations // 4,\n",
    "    # num_iterations // 10,\n",
    "]\n",
    "\n",
    "\n",
    "# Generate all combinations\n",
    "params_all = list(\n",
    "    itertools.product(\n",
    "        test_seed_,\n",
    "        target_update_interval_,\n",
    "        min_epsilon_,\n",
    "        gamma_mm_,\n",
    "        gamma_explore_,\n",
    "        semantic_decay_factor_,\n",
    "        replay_buffer_size_,\n",
    "        warm_start_,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Random combinations with weighted agent_capacity_\n",
    "random_combinations = random.sample(params_all, num_combinations)\n",
    "random_agent_capacity = random.choices(\n",
    "    agent_capacity_, weights=agent_capacity_weights, k=num_combinations\n",
    ")\n",
    "\n",
    "\n",
    "for i, params in tqdm(enumerate(random_combinations)):\n",
    "    (\n",
    "        test_seed,\n",
    "        target_update_interval,\n",
    "        min_epsilon,\n",
    "        gamma_mm,\n",
    "        gamma_explore,\n",
    "        semantic_decay_factor,\n",
    "        replay_buffer_size,\n",
    "        warm_start,\n",
    "    ) = params\n",
    "\n",
    "    capacity = random_agent_capacity[i]\n",
    "\n",
    "    params_dict = {\n",
    "        \"env_str\": \"room_env:RoomEnv-v2\",\n",
    "        \"num_iterations\": num_iterations,\n",
    "        \"replay_buffer_size\": replay_buffer_size,\n",
    "        \"validation_starts_at\": validation_starts_at,\n",
    "        \"warm_start\": warm_start,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"target_update_interval\": target_update_interval,\n",
    "        \"epsilon_decay_until\": num_iterations,\n",
    "        \"max_epsilon\": 1.0,\n",
    "        \"min_epsilon\": min_epsilon,\n",
    "        \"gamma\": {\"mm\": gamma_mm, \"explore\": gamma_explore},\n",
    "        \"capacity\": capacity,\n",
    "        \"pretrain_semantic\": False,\n",
    "        \"semantic_decay_factor\": semantic_decay_factor,\n",
    "        \"lstm_params\": {\n",
    "            \"num_layers\": 2,\n",
    "            \"embedding_dim\": 64,\n",
    "            \"hidden_size\": 64,\n",
    "            \"bidirectional\": False,\n",
    "            \"max_timesteps\": terminates_at + 1,\n",
    "            \"max_strength\": terminates_at + 1,\n",
    "            \"relu_for_attention\": True,\n",
    "        },\n",
    "        \"mlp_params\": {\n",
    "            \"hidden_size\": 64,\n",
    "            \"num_hidden_layers\": 1,\n",
    "            \"dueling_dqn\": True,\n",
    "        },\n",
    "        \"num_samples_for_results\": {\"val\": 5, \"test\": 10},\n",
    "        \"validation_interval\": 5,\n",
    "        \"plotting_interval\": 50,\n",
    "        \"train_seed\": test_seed + 5,\n",
    "        \"test_seed\": test_seed,\n",
    "        \"device\": \"cpu\",\n",
    "        \"qa_function\": \"episodic_semantic\",\n",
    "        \"explore_policy_heuristic\": \"avoid_walls\",\n",
    "        \"env_config\": {\n",
    "            \"question_prob\": 1.0,\n",
    "            \"terminates_at\": terminates_at,\n",
    "            \"randomize_observations\": \"objects\",\n",
    "            \"room_size\": room_size,\n",
    "            \"rewards\": {\"correct\": 1, \"wrong\": 0, \"partial\": 0},\n",
    "            \"make_everything_static\": False,\n",
    "            \"num_total_questions\": 1000,\n",
    "            \"question_interval\": 1,\n",
    "            \"include_walls_in_observations\": True,\n",
    "        },\n",
    "        \"ddqn\": True,\n",
    "        \"default_root_dir\": root_path,\n",
    "    }\n",
    "\n",
    "    agent = DQNAgent(**params_dict)\n",
    "    agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fixed combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True\n",
    "\n",
    "import os\n",
    "from agent import DQNAgent\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "room_size = \"xl-different-prob\"\n",
    "terminates_at = 99\n",
    "num_iterations = (terminates_at + 1) * 100\n",
    "replay_buffer_size = num_iterations\n",
    "validation_starts_at = 0\n",
    "warm_start = num_iterations // 10\n",
    "batch_size = 32\n",
    "target_update_interval = 10\n",
    "gamma_mm = 0.99\n",
    "gamma_explore = 0.9\n",
    "\n",
    "\n",
    "for capacity_max in [12]:\n",
    "    prob_type = (\n",
    "        \"non-equal-object-probs\"\n",
    "        if \"different-prob\" in room_size\n",
    "        else \"equal-object-probs\"\n",
    "    )\n",
    "    root_path = (\n",
    "        f\"./training-results/{prob_type}/dqn/\"\n",
    "        f\"room_size={room_size}/capacity={capacity_max}/\"\n",
    "    )\n",
    "    for test_seed in [0, 1, 2, 3, 4]:\n",
    "\n",
    "        for agent_type in [\"hybrid\", \"semantic\", \"episodic\"]:\n",
    "\n",
    "            if agent_type == \"hybrid\":\n",
    "                capacity = {\n",
    "                    \"episodic\": capacity_max // 2,\n",
    "                    \"semantic\": capacity_max // 2,\n",
    "                    \"short\": 1,\n",
    "                }\n",
    "                semantic_decay_factor_ = [0.70, 0.90, 0.99]\n",
    "                pretrain_semantic_ = [False]\n",
    "            elif agent_type == \"episodic\":\n",
    "                capacity = {\"episodic\": capacity_max, \"semantic\": 0, \"short\": 1}\n",
    "                semantic_decay_factor_ = [1.0]\n",
    "                pretrain_semantic_ = [False]\n",
    "            elif agent_type == \"semantic\":\n",
    "                capacity = {\"episodic\": 0, \"semantic\": capacity_max, \"short\": 1}\n",
    "                semantic_decay_factor_ = [0.70, 0.90, 0.99]\n",
    "                pretrain_semantic_ = [False]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown agent_type: {agent_type}\")\n",
    "\n",
    "            for pretrain_semantic in pretrain_semantic_:\n",
    "                for semantic_decay_factor in semantic_decay_factor_:\n",
    "                    params_dict = {\n",
    "                        \"env_str\": \"room_env:RoomEnv-v2\",\n",
    "                        \"num_iterations\": num_iterations,\n",
    "                        \"replay_buffer_size\": replay_buffer_size,\n",
    "                        \"validation_starts_at\": validation_starts_at,\n",
    "                        \"warm_start\": warm_start,\n",
    "                        \"batch_size\": batch_size,\n",
    "                        \"target_update_interval\": target_update_interval,\n",
    "                        \"epsilon_decay_until\": num_iterations,\n",
    "                        \"max_epsilon\": 1.0,\n",
    "                        \"min_epsilon\": 0.1,\n",
    "                        \"gamma\": {\"mm\": gamma_mm, \"explore\": gamma_explore},\n",
    "                        \"capacity\": capacity,\n",
    "                        \"pretrain_semantic\": pretrain_semantic,\n",
    "                        \"semantic_decay_factor\": semantic_decay_factor,\n",
    "                        \"lstm_params\": {\n",
    "                            \"num_layers\": 2,\n",
    "                            \"embedding_dim\": 64,\n",
    "                            \"hidden_size\": 64,\n",
    "                            \"bidirectional\": False,\n",
    "                            \"max_timesteps\": terminates_at + 1,\n",
    "                            \"max_strength\": terminates_at + 1,\n",
    "                            \"relu_for_attention\": True,\n",
    "                            \"use_one_hot\": True,\n",
    "                        },\n",
    "                        \"mlp_params\": {\n",
    "                            \"hidden_size\": 64,\n",
    "                            \"num_hidden_layers\": 1,\n",
    "                            \"dueling_dqn\": True,\n",
    "                        },\n",
    "                        \"num_samples_for_results\": {\"val\": 10, \"test\": 10},\n",
    "                        \"validation_interval\": 1,\n",
    "                        \"plotting_interval\": 50,\n",
    "                        \"train_seed\": test_seed + 5,\n",
    "                        \"test_seed\": test_seed,\n",
    "                        \"device\": \"cpu\",\n",
    "                        \"qa_function\": \"episodic_semantic\",\n",
    "                        \"explore_policy_heuristic\": \"avoid_walls\",\n",
    "                        \"env_config\": {\n",
    "                            \"question_prob\": 1.0,\n",
    "                            \"terminates_at\": terminates_at,\n",
    "                            \"randomize_observations\": \"objects\",\n",
    "                            \"room_size\": room_size,\n",
    "                            \"rewards\": {\"correct\": 1, \"wrong\": 0, \"partial\": 0},\n",
    "                            \"make_everything_static\": False,\n",
    "                            \"num_total_questions\": 1000,\n",
    "                            \"question_interval\": 1,\n",
    "                            \"include_walls_in_observations\": True,\n",
    "                        },\n",
    "                        \"ddqn\": True,\n",
    "                        \"default_root_dir\": root_path,\n",
    "                    }\n",
    "\n",
    "                    agent = DQNAgent(**params_dict)\n",
    "                    agent.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
